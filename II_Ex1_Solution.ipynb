{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "152c554f",
   "metadata": {},
   "source": [
    "# NLP II - Exercise 1 solution\n",
    "\n",
    "Create a tagger that can detectect the object and the owner of it. Solve it using the EAGLES tags.\n",
    "\n",
    "Create the tagger from scratch, you can't use the cess_esp training set.\n",
    "\n",
    "Your tagger must be able to tag correctly this phrases (as minimum):\n",
    "\n",
    "- Eustaquio tiene un coche amarillo\n",
    "- Hermenegildo tiene un mechero\n",
    "- Sole tiene un huevo de avestruz\n",
    "- María quiere una tele curva\n",
    "- El niño pide tortilla\n",
    "\n",
    "The output have to be a dictionary like this: {\"Person\": \"Eustaquio\", \"Object\": \"Coche amarillo\"}\n",
    "\n",
    "## Libraries\n",
    "\n",
    "We will work with the NLTK library, with the tokeniser included in the library, the cess_esp corpus and the 4 taggers seen in the unit. We will also have to import the NLTK RegEx Parser.\n",
    "\n",
    "Finally, as non-mandatory add-ons that we will use to format or make the work easier, sklearn's train_test_split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8b4e9c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "#Importamos conjunto de entrenamiento\n",
    "from nltk.corpus import cess_esp\n",
    "\n",
    "#Importamos taggers\n",
    "from nltk import UnigramTagger, BigramTagger, TrigramTagger #N-Gram\n",
    "from nltk.tag.hmm import HiddenMarkovModelTagger\n",
    "\n",
    "#Importamos REGEX\n",
    "from nltk.chunk.regexp import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d843404d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizar(_frase):\n",
    "    \n",
    "    return word_tokenize(_frase, 'spanish')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db08221",
   "metadata": {},
   "source": [
    "We tokenise a first sentence to tag it by hand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5af24eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['El', 'niño', 'tiene', 'unos', 'zapatos']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frase = 'El niño tiene unos zapatos'\n",
    "tokens = word_tokenize(frase, 'spanish')\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3e800eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "frase_tags = [[\n",
    "  ('El', 'tdms0'),\n",
    "    ('niño','ncms000'),\n",
    "    ('tiene','vmip3sm'),\n",
    "    ('unos','mcmp00'),\n",
    "    ('zapatos','ncmp000')\n",
    "]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c249106e",
   "metadata": {},
   "source": [
    "Once we have assigned the tokens to the phrase, we move on to train the different taggers and run some tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3d2ec47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "uni1 = UnigramTagger(frase_tags)\n",
    "tri1 = TrigramTagger(frase_tags, backoff=uni1)\n",
    "hmm1 = HiddenMarkovModelTagger.train(frase_tags)\n",
    "\n",
    "\n",
    "uni_es = UnigramTagger(cess_esp.tagged_sents())\n",
    "hmm_es = HiddenMarkovModelTagger.train(cess_esp.tagged_sents())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3f93f7a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('El', 'tdms0'),\n",
       " ('abuelo', None),\n",
       " ('tiene', 'vmip3sm'),\n",
       " ('un', None),\n",
       " ('bastón', None)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frase2 = tokenizar('El abuelo tiene un bastón')\n",
    "tri1.tag(frase2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8308e38c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('El', 'tdms0'),\n",
       " ('abuelo', None),\n",
       " ('tiene', 'vmip3sm'),\n",
       " ('un', None),\n",
       " ('bastón', None)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uni1.tag(frase2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "861bca94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('El', 'tdms0'),\n",
       " ('abuelo', 'ncms000'),\n",
       " ('tiene', 'vmip3sm'),\n",
       " ('un', 'mcmp00'),\n",
       " ('bastón', 'ncmp000')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hmm1.tag(frase2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e7d7fa",
   "metadata": {},
   "source": [
    "We manually add some names to our tagger so that it can recognise them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7efedbae",
   "metadata": {},
   "outputs": [],
   "source": [
    "hmm_es = hmm_es.train([\n",
    "\n",
    "    [('Eustaquio', 'NP00000')],\n",
    "    [('Hermenegildo', 'NP00000')],\n",
    "    [('Sole', 'NP00000')],\n",
    "    [('Rodolfito', 'NP00000')],\n",
    "    [('Marta', 'NP00000')],\n",
    "    [('Pedro', 'NP00000')]\n",
    "\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4f1d4f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\n",
    "    'Eustaquio tiene un coche amarillo',\n",
    "    'Hermenegildo tiene un mechero',\n",
    "    'Sole tiene un huevo de avestruz',\n",
    "    'María quiere una tele curva'\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "163e88f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('Eustaquio', 'sn.e-SUJ'),\n",
       "  ('tiene', 'vmip3s0'),\n",
       "  ('un', 'di0ms0'),\n",
       "  ('coche', 'ncms000'),\n",
       "  ('amarillo', 'aq0ms0')],\n",
       " [('Hermenegildo', 'sn.e-SUJ'),\n",
       "  ('tiene', 'vmip3s0'),\n",
       "  ('un', 'di0ms0'),\n",
       "  ('mechero', 'ncms000')],\n",
       " [('Sole', 'sn.e-SUJ'),\n",
       "  ('tiene', 'vmip3s0'),\n",
       "  ('un', 'di0ms0'),\n",
       "  ('huevo', 'ncms000'),\n",
       "  ('de', 'sps00'),\n",
       "  ('avestruz', 'da0fs0')],\n",
       " [('María', 'sn.e-SUJ'),\n",
       "  ('quiere', 'vmip3s0'),\n",
       "  ('una', 'di0fs0'),\n",
       "  ('tele', 'ncfs000'),\n",
       "  ('curva', 'aq0fs0')]]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frases_tags = []\n",
    "\n",
    "for frase in corpus:\n",
    "    \n",
    "    tokens = tokenizar(frase)\n",
    "    \n",
    "    frases_tags.append(hmm_es.tag(tokens))\n",
    "    \n",
    "frases_tags"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "737b32f5",
   "metadata": {},
   "source": [
    "Now we create the rules for out tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "5a0337de",
   "metadata": {},
   "outputs": [],
   "source": [
    "reglas = r'''\n",
    "\n",
    "Quien: {<sn.e-SUJ>}\n",
    "Qué: <di.*> { <nc.*> <di.*> <aq.*> | <nc.*> <sp.*> <da.*> | <nc.*> <sp.*> <np.*> | <nc.*> <aq.*> | <nc.*> }\n",
    "Qué: {<nc.*> <sp.*> <da.*>}\n",
    "\n",
    "'''\n",
    "\n",
    "parser = nltk.RegexpParser(reglas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "21a122b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parsear(_tokens):\n",
    "    return parser.parse(_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "6ab47523",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (Quien Eustaquio/sn.e-SUJ)\n",
      "  tiene/vmip3s0\n",
      "  un/di0ms0\n",
      "  (Qué coche/ncms000 amarillo/aq0ms0))\n"
     ]
    }
   ],
   "source": [
    "print(parsear(frases_tags[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "774f2334",
   "metadata": {},
   "source": [
    "We create a function to extract the info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "d609d67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extraer(_tree):\n",
    "    \n",
    "    result = {'Quien': None, 'Qué': None}\n",
    "    \n",
    "    objeto = ''\n",
    "    \n",
    "    for nodo in _tree:\n",
    "        \n",
    "        if type(nodo) != tuple:\n",
    "            \n",
    "            if nodo.label() == 'Quien':\n",
    "                word, tag = nodo[0]\n",
    "                result['Quien'] = word\n",
    "            \n",
    "            if nodo.label() == 'Qué':\n",
    "                for elemento in nodo:\n",
    "                    word, tag = elemento\n",
    "                    objeto = objeto + word + ' '\n",
    "                \n",
    "                result['Qué'] = objeto.strip()\n",
    "                \n",
    "    return result\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "412fcfb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Quien': 'Sole', 'Qué': 'huevo de avestruz'}"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extraer(parsear(frases_tags[2]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
